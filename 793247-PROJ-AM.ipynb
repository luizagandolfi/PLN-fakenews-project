{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"figs/LogoUFSCar.jpg\" alt=\"Logo UFScar\" width=\"110\" align=\"left\"/>  <br/> <center>Universidade Federal de São Carlos (UFSCar)<br/><font size=\"4\"> Departamento de Computação, campus Sorocaba</center></font>\n",
    "</p>\n",
    "\n",
    "<font size=\"4\"><center><b>Disciplina: Aprendizado de Máquina</b></center></font>\n",
    "  \n",
    "<font size=\"3\"><center>Prof. Dr. Tiago A. Almeida</center></font>\n",
    "\n",
    "## <center>Projeto Final</center>\n",
    "\n",
    "**Aluno**: Luiza Gandolfi Barioto\n",
    "\n",
    "**RA**: 793247\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho dos arquivos\n",
    "#FILES_DIRECTORY = \"dados\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import fnmatch\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import learning_curve, cross_val_score, train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from scipy.stats import uniform\n",
    "import scipy.sparse\n",
    "\n",
    "from yellowbrick.model_selection import learning_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "import catboost as ctb\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Pré-processamento\n",
    "\n",
    "Nesta seção, as funções da etapa de pré-processamento dos dados devem ser implementadas e aplicadas (se necessário)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset():\n",
    "    def __init__(self, datasets):\n",
    "        self.datasets = datasets\n",
    "\n",
    "    # Criação de um dataframe com todos os dados de treino e teste, com suas respectivas classes (ou ausência delas)\n",
    "    def all_data_dataset(path):\n",
    "        # Lista todos os arquivos CSV no diretório atual que começam com \"news_data\"\n",
    "        files_csv = [file for file in glob.glob(os.path.join(path, 'news_data*.csv')) if fnmatch.fnmatch(file, '*2020.csv')]\n",
    "        combined_data = pd.concat([pd.read_csv(file) for file in tqdm(files_csv)], ignore_index=True)\n",
    "        return combined_data\n",
    "\n",
    "    # Cria um .csv apenas com os dados de treino que tem algum rótulo definido\n",
    "    import pandas as pd\n",
    "\n",
    "    def all_data_train_test(df_original, df_test, df_train):\n",
    "        df_train = df_train.dropna(subset=['label'])\n",
    "        df_train_final = df_original[df_original['id'].isin(df_train['id']) & df_original['date'].between('2020-01-01', '2020-12-31')]\n",
    "        df_train_final = pd.merge(df_train_final, df_train[['id', 'label']], on='id', how='left')\n",
    "        df_train_final = df_train_final.dropna(subset=['title', 'content'])\n",
    "        \n",
    "        df_test_final = df_original[df_original['id'].isin(df_test['id'])]\n",
    "\n",
    "        return df_train_final, df_test_final\n",
    "\n",
    "    # Faz a limpeza dos datasets, removendo pontuacoes, stopwords, etc\n",
    "    # isso é feito apenas na parte do dataset que será realmente usado, para fins de economia de recursos.\n",
    "    \n",
    "    def clean_text(df):\n",
    "        print(\"TITLE\")\n",
    "        print(\"Cleaning empty values\")\n",
    "        df.fillna('empty', inplace=True)\n",
    "        df.title = df.title.astype(str)\n",
    "        print(\"Lower\")\n",
    "        df.title = df.title.str.lower()\n",
    "        print(\"Cleaning characters\")\n",
    "        df.title = df.title.str.replace('[^a-zA-Z0-9 ]', '', regex=True)\n",
    "        print(\"Cleaning digits\")\n",
    "        df.title = df.title.str.replace('\\d*','',regex=True)\n",
    "        print(\"Cleaning www\")\n",
    "        df.title = df.title.str.replace('w{3}','')\n",
    "        print(\"Cleaning https\")\n",
    "        df.title = df.title.str.replace(\"http\\S+\", \"\",regex=True)\n",
    "        print(\"Cleaning spaces\")\n",
    "        df.title = df.title.str.replace('\\s+', ' ',regex=True)\n",
    "        df.title = df.title.str.replace(r'\\s+[a-zA-Z]\\s+', '',regex=True)\n",
    "        print(\"Cleaning stopwords\")\n",
    "        df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "        \n",
    "        print(\"CONTENT\")\n",
    "        print(\"Cleaning empty values\")\n",
    "        df.fillna('empty', inplace=True)\n",
    "        df.content = df.content.astype(str)\n",
    "        print(\"Lower\")\n",
    "        df.content = df.content.str.lower()\n",
    "        print(\"Cleaning characters\")\n",
    "        df.content = df.content.str.replace('[^a-zA-Z0-9 ]', ' ', regex=True)\n",
    "        print(\"Cleaning digits\")\n",
    "        df.content = df.content.str.replace('\\d*','',regex=True)\n",
    "        print(\"Cleaning www\")\n",
    "        df.content = df.content.str.replace('w{3}','')\n",
    "        print(\"Cleaning https\")\n",
    "        df.content = df.content.str.replace(\"http\\S+\", \"\",regex=True)\n",
    "        print(\"Cleaning spaces\")\n",
    "        df.content = df.content.str.replace('\\s+', ' ',regex=True)\n",
    "        df.content = df.content.str.replace(r'\\s+[a-zA-Z]\\s+', '',regex=True)\n",
    "        print(\"Cleaning stopwords\")\n",
    "        df['content'] = df['content'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "        return df\n",
    "        \n",
    "    def balance_df(df_true,df_false):\n",
    "        df_true_downsampled = df_true.sample(df_false.shape[0])\n",
    "        df_balanced = pd.concat([df_true_downsampled, df_false])\n",
    "\n",
    "        print(\"Dataframe balanced\")\n",
    "        return df_balanced\n",
    "\n",
    "    def concat_title_content(df):\n",
    "        df[\"content_title\"] = df[\"title\"] + \" \" + df[\"content\"]\n",
    "        return df\n",
    "\n",
    "    def lemmatize_words(text):\n",
    "        words = text.split()\n",
    "        words = [lemmatizer.lemmatize(word,pos='v') for word in words]\n",
    "        return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    path_all_data = '/kaggle/input/ufscar-am-2023-2-projeto-final'\n",
    "\n",
    "    print(\" *** Creating the datasets ***\")\n",
    "    df_original = CreateDataset.all_data_dataset(path=path_all_data)\n",
    "    df_test_original = pd.read_csv('/kaggle/input/ufscar-am-2023-2-projeto-final/test.csv')\n",
    "    df_train_original = pd.read_csv('/kaggle/input/ufscar-am-2023-2-projeto-final/train.csv')\n",
    "    df_train, df_test = CreateDataset.all_data_train_test(df_original, df_test=df_test_original, df_train=df_train_original)\n",
    "    \n",
    "    print(\"*** Balancing the datasets ***\")\n",
    "    df_train = CreateDataset.balance_df(df_true= df_train[df_train['label']==0], df_false=df_train[df_train['label']==1])\n",
    "    \n",
    "    print(\"*** Cleaning the datasets ***\")\n",
    "    df_train = df_train.dropna()\n",
    "    df_test.fillna('empty',inplace=True)\n",
    "    df_train = CreateDataset.clean_text(df_train)\n",
    "    df_test_clean = CreateDataset.clean_text(df_test)\n",
    "    \n",
    "    print(\"*** Lemmatizing the datasets ***\")\n",
    "    print(\"Lemmatizing the train content\")\n",
    "    df_train[\"content\"] = df_train[\"content\"].astype(str).apply(CreateDataset.lemmatize_words)\n",
    "    print(\"Lemmatizing the train title\")\n",
    "    df_train[\"title\"] = df_train[\"title\"].astype(str).apply(CreateDataset.lemmatize_words)\n",
    "\n",
    "    print(\"Lemmatizing the test content\")\n",
    "    df_test[\"content\"] = df_test[\"content\"].astype(str).apply(CreateDataset.lemmatize_words)\n",
    "    print(\"Lemmatizing the test title\")\n",
    "    df_test[\"title\"] = df_test[\"title\"].astype(str).apply(CreateDataset.lemmatize_words)\n",
    "    \n",
    "    print(\"*** Concatenating the datasets title and content ***\")\n",
    "    df_test[\"content_title\"] = df_test[\"title\"] + \" \" + df_test[\"content\"]\n",
    "    df_train[\"content_title\"] = df_train[\"title\"] + \" \" + df_train[\"content\"]\n",
    "    \n",
    "    print(\"*** Ordering the datasets ***\")\n",
    "    column_train_order = ['id', 'label', 'title', 'content', 'content_title','date','day','month','year']\n",
    "    column_test_order = ['id', 'title', 'content', 'content_title','date','day','month','year']\n",
    "\n",
    "    if set(df_train.columns) == set(column_train_order):\n",
    "        df_train = df_train[column_train_order]\n",
    "\n",
    "    if set(df_test.columns) == set(column_test_order):\n",
    "        df_test = df_test[column_test_order]\n",
    "        \n",
    "    print(\"*** Saving the datasets ***\")\n",
    "    df_train = df_train.dropna()\n",
    "    df_test.fillna('empty',inplace=True)\n",
    "    df_train.to_csv('TRAIN.csv', index=False)\n",
    "    df_test.to_csv('TEST.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**** IF DATASETS ALREADY CREATED, JUST LOAD THEM ****\")\n",
    "df_train = pd.read_csv('/kaggle/working/TRAIN.csv')\n",
    "df_test = pd.read_csv('/kaggle/working/TEST.csv')\n",
    "df_train = df_train.dropna()\n",
    "df_test.fillna('empty',inplace=True)\n",
    "print(\"**** DATASETS LOADED ****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise exploratória\n",
    "\n",
    "Nesta seção, deve ser feita a leitura da base de dados e todas as análises necessárias para interpretar e analisar os dados, tais como:\n",
    "* Significado de cada atributo\n",
    "* Medidas descritivas\n",
    "* Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analisys():\n",
    "    def __init__(self,df,label,X,y,estimator,num_trainings):\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.estimator = estimator\n",
    "        self.num_trainings = num_trainings\n",
    "    \n",
    "    # *** DATA ***\n",
    "    \n",
    "    def pizza_graph(df):\n",
    "        df['year'] = pd.to_datetime(df['date']).dt.year\n",
    "        df_agrupado = df.groupby(['year', 'label']).size().unstack()\n",
    "\n",
    "        for ano in df_agrupado.index.get_level_values('year').unique():\n",
    "            df_ano = df_agrupado.loc[ano]\n",
    "            df_ano.plot.pie(autopct='%1.1f%%', startangle=90, title=f'Distribuição das Classes em {ano}')\n",
    "            plt.ylabel('')  # Remove o rótulo do eixo y\n",
    "            plt.show()\n",
    "    \n",
    "    def wordcloud(df,label):\n",
    "        df_cloud = df[df_train['label'] == label]\n",
    "        comment_words = ''\n",
    "        stopwords = set(STOPWORDS)\n",
    "        \n",
    "        for val in df_cloud.content:\n",
    "            val = str(val)\n",
    "            tokens = val.split()\n",
    "\n",
    "            for i in range(len(tokens)):\n",
    "                tokens[i] = tokens[i].lower()\n",
    "\n",
    "            comment_words += \" \".join(tokens)+\" \"\n",
    "\n",
    "        wordcloud = WordCloud(width = 800, height = 800,\n",
    "                        background_color ='white',\n",
    "                        stopwords = stopwords,\n",
    "                        min_font_size = 10).generate(comment_words)\n",
    "\n",
    "        if label == 1: plt.title('Word Cloud for Fake News',fontsize=17)\n",
    "        else: plt.title('Word Cloud for True News',fontsize=17)\n",
    "\n",
    "        plt.figure(figsize = (8, 8), facecolor = None)\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout(pad = 0)\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def time_series(data):\n",
    "        fake_df = data[data['label'] == 1]\n",
    "        fake=fake_df.groupby(['date'])['label'].count()\n",
    "        fake=pd.DataFrame(fake)\n",
    "\n",
    "        true_df = data[data['label'] == 0]\n",
    "        true=true_df.groupby(['date'])['label'].count()\n",
    "        true=pd.DataFrame(true)\n",
    "\n",
    "        #Plotting the time series graph\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(\n",
    "                 x=true.index,\n",
    "                 y=true['label'],\n",
    "                 name='True',\n",
    "            line=dict(color='blue'),\n",
    "            opacity=0.8))\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "                 x=fake.index,\n",
    "                 y=fake['label'],\n",
    "                 name='Fake',\n",
    "            line=dict(color='red'),\n",
    "            opacity=0.8))\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            rangeslider_visible=True,\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "                    dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                    dict(step=\"all\")\n",
    "                ])\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "        fig.update_layout(title_text='True and Fake News',plot_bgcolor='rgb(248, 248, 255)',yaxis_title='Value')\n",
    "        fig.show()\n",
    "\n",
    "    # *** MODEL ***\n",
    "    def confusion_matrix(actual_label, predicted_label):\n",
    "        actual = np.array(actual_label)\n",
    "        pred = np.array(predicted_label)\n",
    "\n",
    "        cm = confusion_matrix(actual,predicted_label)\n",
    "        sns.heatmap(cm, \n",
    "                    annot=True,\n",
    "                    fmt='g', \n",
    "                    xticklabels=['False','True'],\n",
    "                    yticklabels=['False','True'])\n",
    "        plt.ylabel('Prediction',fontsize=13)\n",
    "        plt.xlabel('Actual',fontsize=13)\n",
    "        plt.title('Confusion Matrix',fontsize=17)\n",
    "        plt.show()\n",
    "        \n",
    "    def roc_curve(model,X_test,y_test):\n",
    "        probs = model.predict_proba(X_test)\n",
    "        preds = probs[:,1]\n",
    "        fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "        # method I: plt\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('*** PIZZA GRAPH ***')\n",
    "    #Gráfico de pizza da distribuição das classes\n",
    "    Analisys.pizza_graph(df_train)\n",
    "    # Nuvem de palavras de notícias falsas\n",
    "    Analisys.wordcloud(df_train,1)\n",
    "    # Nuvem de palavras de notícias verdadeiras\n",
    "    Analisys.wordcloud(df_train,0)\n",
    "    # Frequência das notícias falsas e verdadeiras ao longo de 2019 e 2020.\n",
    "    Analisys.time_series(df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Experimento\n",
    "\n",
    "Nesta seção, o experimento deve ser conduzido, utilizando os protocolos experimentais padrões e testando diferentes modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train['content_title'], df_train['label'], test_size=0.1,stratify=df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_train_vectors = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test_vectors = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINE TUNING\n",
    "X = tfidf_train_vectors[:10000]\n",
    "y = y_train[:10000]\n",
    "\n",
    "params = {'C': uniform(0.1, 2.0),  \n",
    "          'max_iter': [1500, 2000, 5000],\n",
    "          'tol': [0.00001, 0.0001, 0.01, 0.1]}\n",
    "\n",
    "clf = LogisticRegression()\n",
    "search_cv_lr = RandomizedSearchCV(clf, params, n_iter=10, cv=5,  n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "search_cv_lr.fit(X, y)\n",
    "search_cv_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(**search_cv_lr.best_params_)\n",
    "LR.fit(tfidf_train_vectors,y_train)\n",
    "\n",
    "predicted_LR = LR.predict(tfidf_test_vectors)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted_LR))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted_LR))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINE TUNING\n",
    "tfidf_array = tfidf_train_vectors.toarray()\n",
    "tfidf_test = tfidf_test_vectors.toarray()\n",
    "\n",
    "X = tfidf_array.tolist()\n",
    "y = y_train.values.tolist()\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "params = {'var_smoothing':np.logspace(0,-9, num=10)}\n",
    "\n",
    "clf = GaussianNB()\n",
    "search_cv_nb = RandomizedSearchCV(clf, params, n_iter=10, cv=5,  n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "search_cv_nb.fit(X,y)\n",
    "search_cv_nb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_array = tfidf_train_vectors.toarray()\n",
    "tfidf_test = tfidf_test_vectors.toarray()\n",
    "\n",
    "X = tfidf_array.tolist()\n",
    "test = tfidf_test.tolist()\n",
    "y = y_train.values.tolist()\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = GaussianNB(**search_cv_nb.best_params_)\n",
    "NB.fit(X, y)\n",
    "\n",
    "predicted_NB = NB.predict(test)\n",
    "\n",
    "print(\"NB Accuracy:\",metrics.accuracy_score(y_test, predicted_NB))\n",
    "print(\"NB Precision:\",metrics.precision_score(y_test, predicted_NB))\n",
    "print(\"NB Recall:\",metrics.recall_score(y_test, predicted_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINE TUNING\n",
    "X = tfidf_train_vectors[:10000]\n",
    "y = y_train[:10000]\n",
    "\n",
    "params = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive']\n",
    "}\n",
    "\n",
    "clf = MLPClassifier()\n",
    "search_cv_mlp = RandomizedSearchCV(clf, params, n_iter=10, cv=5,  n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "search_cv_mlp.fit(X, y)\n",
    "search_cv_mlp.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(**search_cv_mlp.best_params_)\n",
    "MLP.fit(tfidf_train_vectors, y_train)\n",
    "\n",
    "predicted_MLP = MLP.predict(tfidf_test_vectors)\n",
    "\n",
    "print(\"MLP Accuracy:\",metrics.accuracy_score(y_test, predicted_MLP))\n",
    "print(\"MLP Precision:\",metrics.precision_score(y_test, predicted_MLP))\n",
    "print(\"MLP Recall:\",metrics.recall_score(y_test, predicted_MLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINE TUNING\n",
    "X = tfidf_train_vectors[:10000]\n",
    "y = y_train[:10000]\n",
    "\n",
    "params = {'C':[0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "clf = LinearSVC()\n",
    "search_cv_svm =  RandomizedSearchCV(clf, params, n_iter=10, cv=5,  n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "search_cv_svm.fit(X,y)\n",
    "search_cv_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(**search_cv_svm.best_params_)\n",
    "SVM = CalibratedClassifierCV(model)\n",
    "SVM.fit(tfidf_train_vectors,y_train)\n",
    "\n",
    "predicted_SVM = SVM.predict(tfidf_test_vectors)\n",
    "\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(y_test, predicted_SVM))\n",
    "print(\"SVM Precision:\",metrics.precision_score(y_test, predicted_SVM))\n",
    "print(\"SVM Recall:\",metrics.recall_score(y_test, predicted_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINE TUNING\n",
    "X = tfidf_train_vectors[:10000]\n",
    "y = y_train[:10000]\n",
    "\n",
    "params = {'bootstrap': [True, False],\n",
    "          'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "          'max_features': ['auto', 'sqrt','log2'],\n",
    "          'min_samples_leaf': [1, 2, 4],\n",
    "          'min_samples_split': [2, 5, 10],\n",
    "          'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "search_cv_rf =  RandomizedSearchCV(clf, params, n_iter=10, cv=5,  n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "search_cv_rf.fit(X,y)\n",
    "search_cv_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(**search_cv_rf.best_params_)\n",
    "RF.fit(tfidf_train_vectors,y_train)\n",
    "\n",
    "predicted_RF = RF.predict(tfidf_test_vectors)\n",
    "\n",
    "print(\"Random Forest Accuracy:\",metrics.accuracy_score(y_test, predicted_RF))\n",
    "print(\"Random Forest Precision:\",metrics.precision_score(y_test, predicted_RF))\n",
    "print(\"Random Forest Recall:\",metrics.recall_score(y_test, predicted_RF))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINE TUNING\n",
    "X = tfidf_train_vectors[:10000]\n",
    "y = y_train[:10000]\n",
    "\n",
    "params = {'learning_rate':[0.01,0.03,0.05,0.1,0.15,0.2],\n",
    "          'n_estimators':[100,200,500,1000,2000],\n",
    "          'max_depth':[3,5,10],\n",
    "          'colsample_bytree':[0.1,0.3,0.5,1],\n",
    "          'subsample':[0.1,0.3,0.5,1]}\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "search_cv_xgb =  RandomizedSearchCV(clf, params, n_iter=10, cv=5,  n_jobs=-1, scoring='accuracy', return_train_score=True, verbose=10)\n",
    "search_cv_xgb.fit(X,y)\n",
    "search_cv_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(**search_cv_xgb.best_params_)\n",
    "xgb_model.fit(tfidf_train_vectors, y_train)\n",
    "\n",
    "predicted_XG = xgb_model.predict(tfidf_test_vectors)\n",
    "\n",
    "print(\"XGB Accuracy:\",metrics.accuracy_score(y_test, predicted_XG))\n",
    "print(\"XGB Precision:\",metrics.precision_score(y_test, predicted_XG))\n",
    "print(\"XGB Recall:\",metrics.recall_score(y_test, predicted_XG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINE TUNING\n",
    "X = tfidf_train_vectors[:10000]\n",
    "y = y_train[:10000]\n",
    "\n",
    "params = { \"learning_rate\": np.linspace(0,0.2,5),\n",
    "          \"max_depth\": randint(3, 10)}\n",
    "\n",
    "clf = ctb.CatBoostClassifier()\n",
    "search_cv_ctb =  RandomizedSearchCV(clf, params, n_iter=10, cv=5,  n_jobs=-1, scoring='accuracy', return_train_score=True, verbose=10)\n",
    "search_cv_ctb.fit(X,y)\n",
    "search_cv_ctb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CBC = ctb.CatBoostClassifier(**search_cv_ctb.best_params_)\n",
    "model_CBC.fit(tfidf_train_vectors, y_train)\n",
    "\n",
    "predicted_CTB = model_CBC.predict(tfidf_test_vectors)\n",
    "\n",
    "print(\"CTB Accuracy:\",metrics.accuracy_score(y_test, predicted_CTB))\n",
    "print(\"CTB Precision:\",metrics.precision_score(y_test, predicted_CTB))\n",
    "print(\"CTB Recall:\",metrics.recall_score(y_test, predicted_CTB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENSEMBLE - LR + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegression()\n",
    "model2 = RandomForestClassifier()\n",
    "\n",
    "model_rf_lr = VotingClassifier(estimators=[('lr', model1),('rf', model2)], voting='soft')\n",
    "model_rf_lr.fit(tfidf_train_vectors,y_train)\n",
    "\n",
    "predicted_rf_lr = model_rf_lr.predict(tfidf_test_vectors)\n",
    "\n",
    "print(\"ENSEMBLE Accuracy:\",metrics.accuracy_score(y_test, predicted_rf_lr))\n",
    "print(\"ENSEMBLE Precision:\",metrics.precision_score(y_test, predicted_rf_lr))\n",
    "print(\"ENSEMBLE Recall:\",metrics.recall_score(y_test, predicted_rf_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENSEMBLE - SVM + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = LinearSVC()\n",
    "SVM = CalibratedClassifierCV(model_svm)\n",
    "\n",
    "model1 = RandomForestClassifier()\n",
    "model2 = SVM\n",
    "\n",
    "model_rf_svm = VotingClassifier(estimators=[('rf', model1),('svm', model2)], voting='soft')\n",
    "model_rf_svm.fit(tfidf_train_vectors,y_train)\n",
    "\n",
    "predicted_svm_rf = model_rf_svm.predict(tfidf_test_vectors)\n",
    "\n",
    "print(\"ENSEMBLE Accuracy:\",metrics.accuracy_score(y_test, predicted_svm_rf))\n",
    "print(\"ENSEMBLE Precision:\",metrics.precision_score(y_test, predicted_svm_rf))\n",
    "print(\"ENSEMBLE Recall:\",metrics.recall_score(y_test, predicted_svm_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENSEMBLE - LR + SVM + XGB + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = LinearSVC()\n",
    "SVM = CalibratedClassifierCV(model_svm)\n",
    "\n",
    "model1 = xgb.XGBClassifier()\n",
    "model2 = LogisticRegression()\n",
    "model3 = SVM\n",
    "model4 = RandomForestClassifier()\n",
    "\n",
    "model_svm_rf_lr_xgb = VotingClassifier(estimators=[('xgb', model1), ('lr', model2),('svm', model3), ('rf', model4)], voting='soft')\n",
    "model_svm_rf_lr_xgb.fit(tfidf_train_vectors,y_train)\n",
    "\n",
    "predicted_ENS = model_svm_rf_lr_xgb.predict(tfidf_test_vectors)\n",
    "\n",
    "print(\"ENSEMBLE Accuracy:\",metrics.accuracy_score(y_test, predicted_ENS))\n",
    "print(\"ENSEMBLE Precision:\",metrics.precision_score(y_test, predicted_ENS))\n",
    "print(\"ENSEMBLE Recall:\",metrics.recall_score(y_test, predicted_ENS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise dos Resultados\n",
    "\n",
    "Nesta seção, os resultados devem ser exibidos através de tabelas e gráficos, comparados e profundamente analisados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "Analisys.confusion_matrix(actual_label=y_test,predicted_label=predicted_LR)\n",
    "# ROC Curve\n",
    "Analisys.roc_curve(LR,tfidf_test_vectors,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "Analisys.confusion_matrix(actual_label=y_test,predicted_label=predicted_NB)\n",
    "# ROC Curve\n",
    "Analisys.roc_curve(NB,test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "Analisys.confusion_matrix(actual_label=y_test,predicted_label=predicted_MLP)\n",
    "# ROC Curve\n",
    "Analisys.roc_curve(MLP,tfidf_test_vectors,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "Analisys.confusion_matrix(actual_label=y_test,predicted_label=predicted_SVM)\n",
    "# ROC Curve\n",
    "Analisys.roc_curve(SVM,tfidf_test_vectors,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "Analisys.confusion_matrix(actual_label=y_test,predicted_label=predicted_RF)\n",
    "# ROC Curve\n",
    "Analisys.roc_curve(RF,tfidf_test_vectors,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "Analisys.confusion_matrix(actual_label=y_test,predicted_label=predicted_XG)\n",
    "# ROC Curve\n",
    "Analisys.roc_curve(xgb_model,tfidf_test_vectors,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "Analisys.confusion_matrix(actual_label=y_test,predicted_label=predicted_CTB)\n",
    "# ROC Curve\n",
    "Analisys.roc_curve(model_CBC,tfidf_test_vectors,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENSEMBLE - LR + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "Analisys.confusion_matrix(actual_label=y_test,predicted_label=predicted_rf_lr)\n",
    "# ROC Curve\n",
    "Analisys.roc_curve(model_rf_lr,tfidf_test_vectors,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENSEMBLE SVM + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "Analisys.confusion_matrix(actual_label=y_test,predicted_label=predicted_svm_rf)\n",
    "# ROC Curve\n",
    "Analisys.roc_curve(model_rf_svm,tfidf_test_vectors,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENSEMBLE LR + SVM + XGB + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "Analisys.confusion_matrix(actual_label=y_test,predicted_label=predicted_ENS)\n",
    "# ROC Curve\n",
    "Analisys.roc_curve(model_svm_rf_lr_xgb,tfidf_test_vectors,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SALVAR OS RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df_test_vectors = tfidf_vectorizer.transform(df_test['content_title'])\n",
    "model_prob = model_CBC.predict_proba(tfidf_df_test_vectors)\n",
    "\n",
    "prob = pd.DataFrame(model_prob, columns=['pred_0', 'pred_1'])\n",
    "prob['output'] = prob['pred_1']\n",
    "\n",
    "df_final = pd.DataFrame()\n",
    "df_final['id'] = df_test['id']\n",
    "df_final['label'] = prob['output']\n",
    "\n",
    "df_final.to_csv('result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
